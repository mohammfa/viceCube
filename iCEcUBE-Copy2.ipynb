{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammfa/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all values greater than a certain value\n",
    "def findGreater(mat,val):\n",
    "    arr = np.array([])\n",
    "    for i in range(mat.shape[0]): #xaxis\n",
    "        for j in range(mat.shape[1]): #yaxix\n",
    "            if(mat[i,j] > val):\n",
    "                arr = np.append(arr,mat[i,j])\n",
    "                \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Def Generate neutrino \n",
    "Random origin (x,y)\n",
    "Random direction (dx, dy) or (one angles)\n",
    "Random energy (0 to 1) or (10 to 300 nanoseconds)\n",
    "Random time\n",
    "(make code adjustable)\n",
    "We want to know how fast the neutrino is\"\"\"\n",
    "def generateNeutrino():\n",
    "    x = random.uniform(0,10)\n",
    "    y = random.uniform(0,10)\n",
    "    angle = random.vonmisesvariate(0, 0)\n",
    "    energy = random.random();\n",
    "    time = random.randint(10,300)\n",
    "\n",
    "    return x, y, angle, energy, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSignal(x,y,angle,energy,time):\n",
    "    nodes = 10\n",
    "    x_arr = np.linspace(0,nodes,nodes + 1)\n",
    "    y_arr = np.linspace(0,nodes,nodes + 1)\n",
    "    #10 by 10 grid which is the VICE CUBE\n",
    "    \n",
    "    #using MeshGrid\n",
    "    mesh_x, mesh_y = np.meshgrid(x_arr, y_arr)\n",
    "\n",
    "    #find distance of each sensor to the origion using euclidean distance formula\n",
    "    x_sq = mesh_x - x\n",
    "    y_sq = mesh_y - y\n",
    "    x_sq = np.power(x_sq,2)\n",
    "    y_sq = np.power(y_sq,2)\n",
    "    distance = np.sqrt(x_sq + y_sq)\n",
    "    \n",
    "    #find charge\n",
    "    #charge formula: C = (maxDistance - distance_to_each_node)^2 / maxDistance\n",
    "    maxDistance = math.sqrt((nodes * nodes) + (nodes * nodes))\n",
    "    charge = np.power((maxDistance - distance),2) / pow(maxDistance,2)\n",
    "    \n",
    "    \n",
    "    #based on the angle and the origin create a line (data fit) that would simulate a neutrino path\n",
    "    return mesh_x, mesh_y, distance, charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exampleRun():\n",
    "    x,y,angle,energy,time = generateNeutrino();\n",
    "    mesh_x, mesh_y, distance, charge = generateSignal(x,y,angle,energy,time)\n",
    "    #print(\"x\\n\", mesh_x)\n",
    "    #print(\"y\\n\", mesh_y)\n",
    "\n",
    "    plt.plot(mesh_x,mesh_y, marker='.', color='k', linestyle='none')\n",
    "    \n",
    "    \n",
    "    CS = plt.contourf(mesh_x, mesh_y,charge, 15, cmap=plt.cm.rainbow,\n",
    "                  vmax=charge.max(), vmin=0)\n",
    "    plt.colorbar()  \n",
    "    plt.show()\n",
    "\n",
    "    print(\"x y angle energy time\")\n",
    "    print(x,y,angle,energy,time)\n",
    "    \n",
    "    #print(\"distance\\n\", distance)\n",
    "    print(\"charge\\n\", charge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#decompose signal function\n",
    "\"\"\"\" function to decompose the signal to create a training vector and a training label\n",
    "def decomposeSignal():\n",
    "    \"\"\"\n",
    "#plan is to use have a vector of which sensors detected the neutrino and then have a vector for distance, charge\n",
    "#then use that as the training data\n",
    "\n",
    "def createTrainingVector(dataSize):\n",
    "\n",
    "    xy = np.zeros(2)\n",
    "    trainVec = np.zeros((dataSize,121),dtype = np.float32)\n",
    "    trainLabel = np.zeros((dataSize,2), dtype = np.int64)\n",
    "\n",
    "    for i in range(dataSize):\n",
    "        x_o,y_o,angle,energy,time = generateNeutrino();\n",
    "        mesh_x, mesh_y, distance, charge = generateSignal(x_o,y_o,angle,energy,time)\n",
    "        xy[0] = x_o\n",
    "        xy[1] = y_o\n",
    "        #flattening the charge matrix to a vector\n",
    "        chargeVector = charge.flatten()\n",
    "        trainVec[i,:] = chargeVector\n",
    "        trainLabel[i,:] = xy\n",
    "    \n",
    "    return trainVec, trainLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputFunction(dataSize):\n",
    "    trainVec, trainLabel = createTrainingVector(dataSize)    \n",
    "    features = {'x' : trainVec}\n",
    "    #trainLabel is the output. which currently is the origin\n",
    "    labels = trainLabel\n",
    "    #labels = np.int(labels)\n",
    "    \n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for some reason this does not work. I however found another approach with using tf.estimator.inputs.numpy_input_fn\n",
    "def trainInputFn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    print(type(features))\n",
    "\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    return dataset.shuffle(1000).repeat().batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "int64\n",
      "(1200, 121)\n",
      "(1200, 2)\n",
      "float32\n",
      "int64\n",
      "(25, 121)\n",
      "(25, 2)\n",
      "feature_columns= []\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/gn/y5s233mx34b21b029nk5sc3h0000gn/T/tmp6jji6wrr\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/gn/y5s233mx34b21b029nk5sc3h0000gn/T/tmp6jji6wrr', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0xb1eb885f8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/gn/y5s233mx34b21b029nk5sc3h0000gn/T/tmp6jji6wrr/model.ckpt.\n",
      "INFO:tensorflow:loss = 6103.4985, step = 1\n",
      "INFO:tensorflow:global_step/sec: 539.596\n",
      "INFO:tensorflow:loss = 109.55486, step = 101 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 838.153\n",
      "INFO:tensorflow:loss = 73.24077, step = 201 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 892.538\n",
      "INFO:tensorflow:loss = 38.711403, step = 301 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 786.509\n",
      "INFO:tensorflow:loss = 32.660557, step = 401 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 816.433\n",
      "INFO:tensorflow:loss = 28.705063, step = 501 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 828.289\n",
      "INFO:tensorflow:loss = 27.804743, step = 601 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 782.41\n",
      "INFO:tensorflow:loss = 46.014423, step = 701 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 796.831\n",
      "INFO:tensorflow:loss = 26.28945, step = 801 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 818.131\n",
      "INFO:tensorflow:loss = 26.248314, step = 901 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 816.2\n",
      "INFO:tensorflow:loss = 25.778511, step = 1001 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 817.721\n",
      "INFO:tensorflow:loss = 27.280634, step = 1101 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 895.721\n",
      "INFO:tensorflow:loss = 26.731407, step = 1201 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 761.909\n",
      "INFO:tensorflow:loss = 22.51936, step = 1301 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 706.155\n",
      "INFO:tensorflow:loss = 30.637253, step = 1401 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.621\n",
      "INFO:tensorflow:loss = 21.20637, step = 1501 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 832.856\n",
      "INFO:tensorflow:loss = 24.557983, step = 1601 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 800.589\n",
      "INFO:tensorflow:loss = 21.40323, step = 1701 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 687.469\n",
      "INFO:tensorflow:loss = 24.711288, step = 1801 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 717.983\n",
      "INFO:tensorflow:loss = 23.398415, step = 1901 (0.138 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /var/folders/gn/y5s233mx34b21b029nk5sc3h0000gn/T/tmp6jji6wrr/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 22.694618.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0xb1eb88358>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if __name__== \"__main__\":\n",
    "trainSize = 1200\n",
    "testSize = 25\n",
    "\n",
    "features, labels = inputFunction(trainSize)\n",
    "\n",
    "print((features['x'].dtype))\n",
    "print(labels.dtype)\n",
    "print(features['x'].shape)\n",
    "print(labels.shape)\n",
    "\n",
    "testFeatures, testLabels = inputFunction(testSize)\n",
    "print((testFeatures['x'].dtype))\n",
    "print(testLabels.dtype)\n",
    "print(testFeatures['x'].shape)\n",
    "print(testLabels.shape)\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(x=(features),\n",
    "                                                    y=(labels),\n",
    "                                                    num_epochs=None,\n",
    "                                                    shuffle=True)\n",
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(x=(testFeatures),\n",
    "                                                   y=(testLabels),\n",
    "                                                   num_epochs=1,\n",
    "                                                   shuffle=False)\n",
    "\n",
    "my_feature_columns = []\n",
    "print(\"feature_columns=\",my_feature_columns)\n",
    "\n",
    "# Specify that all features have real-value data\n",
    "my_feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[121])]\n",
    "\n",
    "# Build 3 layer DNN Regressor with 10, 20, 10 units respectively.\n",
    "regressor = tf.estimator.DNNRegressor(feature_columns=my_feature_columns,\n",
    "                                      label_dimension = 2,\n",
    "                                      hidden_units=[10, 20, 10])\n",
    "\n",
    "regressor.train(input_fn=train_input_fn, steps=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function numpy_input_fn.<locals>.input_fn at 0xb1faf31e0>\n",
      "<class 'function'>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-09-19:54:02\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/gn/y5s233mx34b21b029nk5sc3h0000gn/T/tmp6jji6wrr/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-09-19:54:02\n",
      "INFO:tensorflow:Saving dict for global step 2000: average_loss = 0.080892056, global_step = 2000, loss = 4.044603\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "\n",
      " Test Accuracy= {'average_loss': 0.080892056, 'loss': 4.044603, 'global_step': 2000}\n",
      "\n",
      "Test set accuracy: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy.\n",
    "print(test_input_fn)\n",
    "print(type(test_input_fn))\n",
    "\n",
    "\n",
    "evalReg = regressor.evaluate(input_fn = test_input_fn)\n",
    "print(type(evalReg))\n",
    "print(\"\\n\\n\\n Test Accuracy=\",evalReg)\n",
    "print('\\nTest set accuracy: \\n'.format(**evalReg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md               iCEcUBE-Copy1.ipynb     iris_test.csv\r\n",
      "helloWorldExample.ipynb iCEcUBE.ipynb           iris_training.csv\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
